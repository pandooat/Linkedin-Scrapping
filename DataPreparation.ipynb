{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eecf9f44",
   "metadata": {},
   "source": [
    "## Data Understanding and Data Cleansing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e353ca",
   "metadata": {},
   "source": [
    "In this part, I will try to see:\n",
    "* what the data is about\n",
    "* the meaning of each fields, if visible\n",
    "* the rules of each fields, if visible\n",
    "* data relevancy\n",
    "* Role distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11c951",
   "metadata": {},
   "source": [
    "This is a dataset that contains the first 991 Linkedin job lists under the keywords \"Data Science\" located in \"Indonesia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bbc1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416ae29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file path to where you put the excel file to load\n",
    "output_file_path = 'C:/Users/Miranti/Documents/_WORK/Portofolio/linkedinwebscraping/DataScience.xlsx'\n",
    "df = pd.read_excel(output_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00af1adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d5e15",
   "metadata": {},
   "source": [
    "### Split City, Province, Country in Location Field\n",
    "\n",
    "Comma-separated. There are 3 ways the location is formatted. i.e:\n",
    "* Jakarta metropolitan area --?> 1 field\n",
    "* Greater Jakarta --> 1 field\n",
    "* Greater Semarang --> 1 field\n",
    "* Badung, Bali, Indonesia --> 3 fields\n",
    "* Bali, Indonesia --> 2 fields\n",
    "\n",
    "If only 1 field : [city] / [country]\n",
    "\n",
    "If 2 fields : [Province, country]\n",
    "\n",
    "If 3 fields : [city, province, country]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f5c1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "City = []\n",
    "Province = []\n",
    "for row in df['Location']:\n",
    "    x = row.split(\",\") #convert each element in the tuple to list\n",
    "    n_element = len(x) #check how many element in the field (list length)\n",
    "    #print(n_element) \n",
    "    if n_element == 3:\n",
    "        City.append(x[0]) #take the first element as city\n",
    "        Province.append(x[1]) #take the second element as province\n",
    "    elif n_element == 2:\n",
    "        City.append(np.nan)\n",
    "        Province.append(x[0])\n",
    "    else:\n",
    "        if x[0] == 'Indonesia':\n",
    "            City.append(np.nan)\n",
    "            Province.append(np.nan)\n",
    "        else:\n",
    "            City.append(x[0])\n",
    "            Province.append(np.nan)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414f5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert new columns after location. location starts from 0.\n",
    "df.insert(5, 'City', City)\n",
    "df.insert(6, 'Province', Province)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b59f141",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c5550",
   "metadata": {},
   "source": [
    "### Fix Content of Job Level and Type\n",
    "\n",
    "Turns out, when a job post doesn't have any Job level but has Job type, the content in the field 'Type' is shifted into 'Level'. Upon further inspection, this happened because we find the HTML element by XPATH, which relies on the order of the element. So when the element in the first order is empty, the second element will automatically fill the first one.\n",
    "\n",
    "I tried to get the element by class name, but turns out there were no distinguishable name.\n",
    "\n",
    "Thus, for better data accuracy, we need to fix this. But first, we need to define the fields."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97119337",
   "metadata": {},
   "source": [
    "#### Field Definition\n",
    "\n",
    "* Level : the seniority level expected for a job. i.e. (Entry-level, Mid-to-Senior Level, Associate, Director, Executive)\n",
    "* Type : Employment type of the job, i.e. (Full-time, part-time, internship, temporary, contract)\n",
    "* Function : The Department or Job function this role falls into\n",
    "* Industry : The field of the company in general\n",
    "\n",
    "When there are Type contents in the Level field, we can safely assume that the job does not have seniority Level listed.\n",
    "For all rows where Level is Full-time/part-time/internship/temporary/contract, we can shift the content into Type field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce5760",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_list = ['Full-time', 'Part-time', 'Internship', 'Temporary', 'Contract']\n",
    "new_level = []\n",
    "new_type = []\n",
    "length = len(df['Level'])\n",
    "df_level = df['Level']\n",
    "df_type = df['Type']\n",
    "for row in range(length):\n",
    "    if str(df_level.iloc[row]) in fix_list:\n",
    "        new_level.append(np.nan)\n",
    "        new_type.append(df_level.iloc[row]) #iloc = integer location. Function to select row by its index location\n",
    "    else:\n",
    "        new_level.append(df_level.iloc[row])\n",
    "        new_type.append(df_type.iloc[row])\n",
    "#Insert new columns after location. location starts from 0.\n",
    "df['Level'] = new_level\n",
    "df['Type'] = new_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871680c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95878e7",
   "metadata": {},
   "source": [
    "### Categorize and Remove unrelated Jobs\n",
    "\n",
    "Even though we used the keywords \"Data Scientist\", turns out not all job is related to Data Scientist. Some are just General Software Developer, or Python Programmer. Even the \"Data Scientist\" jobs might come under different role name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ef349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc094ed",
   "metadata": {},
   "source": [
    "It might be useful to categorize them into more general job name for the sake of filtering simplicity. So when we want to work with Data Science jobs only, we can easily remove the unrelated jobs more easily later on.\n",
    "\n",
    "By quickly looking at our data, if the job title contains the words:\n",
    "* data science\n",
    "* data scientist\n",
    "* machine learning\n",
    "* artificial intelligence\n",
    "* AI/ML\n",
    "* ML\n",
    "* AI Engineer\n",
    "\n",
    "we can categorize them into Data Scientist. Otherwise, we will mark them as 'Others'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Title'] = df['Title'].str.lower() #convert all values in Title to lowercase\n",
    "keyword_list= ['data science', 'data scientist', 'machine learning', 'artificial intelligence', 'ai/ml', 'ml', 'ai engineer']\n",
    "swe_list = ['software','software engineer', 'programmer', 'full stack', 'application', 'developer']        \n",
    "fe_list = ['front-end', 'front end', 'frontend', 'frontend developer']\n",
    "be_list = ['back end', 'back-end', 'backend developer']\n",
    "length = len(df['Title'])\n",
    "df_title = df['Title']\n",
    "title_category = []\n",
    "for row in range(length):\n",
    "    if any(element in str(df_title.iloc[row]) for element in keyword_list)==True:\n",
    "        title_category.append('Data Science')\n",
    "    elif any(element in str(df_title.iloc[row]) for element in fe_list)==True:\n",
    "        title_category.append('Front-End Engineer')\n",
    "    elif any(element in str(df_title.iloc[row]) for element in be_list)==True:\n",
    "        title_category.append('Back-End Engineer')\n",
    "    elif any(element in str(df_title.iloc[row]) for element in swe_list)==True:\n",
    "        title_category.append('Software Engineer')\n",
    "    else:\n",
    "        title_category.append('Others')\n",
    "\n",
    "#Insert new columns after location. location starts from 0.\n",
    "df['Title Category'] = title_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87ab9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb336bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the total records by title category\n",
    "df['Title Category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be67ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice only job lists with title category = Data Science\n",
    "df_ds = df[df['Title Category']=='Data Science']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e083629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice only job lists with title category = Software Engineer\n",
    "# This is just a sample, for checking purpose\n",
    "df_swe = df[df['Title Category']=='Software Engineer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a504d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d46069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_swe.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5614b7ed",
   "metadata": {},
   "source": [
    "### Select important column for Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263f292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Description', inplace=True, axis=1)\n",
    "df.drop('ID', inplace=True, axis=1)\n",
    "df_clean = df\n",
    "df_clean.columns = ['date', 'company', 'title', 'location','city','province','level','type','function','industry','title_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77eddf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b70770b",
   "metadata": {},
   "source": [
    "### Export to excel or csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4ddb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path_excel = 'C:/Users/Miranti/Documents/_WORK/Portofolio/linkedinwebscraping/DataScienceProcessed.xlsx'\n",
    "output_file_path_csv = 'C:/Users/Miranti/Documents/_WORK/Portofolio/linkedinwebscraping/DataScienceProcessed.csv'\n",
    "df_ds.to_excel(output_file_path_excel, index=False)\n",
    "df.to_csv(output_file_path_csv, sep='$', index=False) #csv separator used = '$'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
